---
layout: post
date: 2016-01-15
description: K-Means using Python, Numpy & Matplotlib
categories:
- code
- data-mining
- clustering
permalink: blog/kmeans-part-2/
headline: blog
heading: K-Means | Part II
---

In the [last article](/blog/kmeans-part-1) we took a look at a simple k-means implementation using Python. In this article we will sophisticate our previous work by doing away with hard coded data, replacing the Vec class with [Numpy](http://www.numpy.org/) arrays and visualizing results using [matplotlib](http://matplotlib.org/). The source code for this iteration can be found [here](https://github.com/jeremyfromearth/k-means). We will not go through it line by line, but we will look at the most significant improvements.

## Loading Data
Firstly, let us look at loading and cleaning up the SPAETH data sets. Each data file has a description at the top of the file where. Each line of the description is preceded with a hash symbol. We'll read the file line by line and ignore any lines that begin with the hash symbol and we'll strip out new lines as well.

{% highlight python %}
data_file = sys.argv[1]
lines = [
   line.strip('\n') for line in open(data_file) if '#' not in line
]
{% endhighlight %}

As you can see we get the path to the file as a command line argument. This means that we can load any of the datasets into our program like so:

`python kmeans.py data/spaeth_01.txt`

## Replacing Vec with Numpy
Previously we used a custom class called `Vec` to represent our two dimensional data. In this iteration, we'll move to using Numpy arrays. This switch is pretty straightforward, though there are a couple of points of interest. Our Vec class had a static method called distance() that returned the distance between two vectors. Numpy doesn't provide this function directly, so to achieve this we use a method from the `linalg` (linear algebra) module that is part of Numpy.

{% highlight python %}
>> import numpy as np
>> v1 = np.array([3, 4])
>> v2 = np.array([0, 0])
>> np.linalg.norm(v1 - v2)
>> 5.0
{% endhighlight %}

When testing for convergence, we need to check the equality of two Numpy arrays. Previously we just defined the double equals for the Vec class which enabled us to compare to lists of vectors. Using Numpy, this can be accomplished as follows:

`np.array_equal(means, new_means)`

## Adding Visualization
The last big change in this iteration is the addition of visualizing the results. To do this we use matplotlib. At the end of the script we include this simple code to create some nice visualizations of the data and the results of the clustering algorithm.

{% highlight python %}
from collections import deque
from matplotlib import pyplot as plt
from matplotlib import style

x = [data[0] for v in data]
y = [data[1] for v in data]
colors = deque(['b', 'r', 'w', 'k', 'c', 'm', 'y', 'g', 'orange', 'brown'])
for k in clusters:
    x = [v[0] for v in clusters[k]]
    y = [v[1] for v in clusters[k]]
    plt.scatter(x, y, color=colors[0])
    colors.rotate()

for mean in means:
    x = [v[0] for v in means]
    y = [v[1] for v in means]
    plt.scatter(x, y, color='r', s=32, alpha=0.3)

plt.title('K-means Clustering : %d Iterations' % (iterations))
plt.ylabel('Y')
plt.xlabel('X')
plt.show()
{% endhighlight %}

Below are the results from two of the files in our data set. The red dots indicate the “means” or “centroids” of each group.

![k-means 9 iterations on spaeth 4](/assets/images/blog/k-means-9-iters-spaeth-04.png)
__k-means with 9 iterations for spaeth_04.txt__

![k-means 4 iterations on spaeth 7](/assets/images/blog/k-means-4-iters-spaeth-07.png)
__k-means with 4 iterations for spaeth_07.txt__

One known issue with k-means is that the results can be different per run, based upon the initial random means.

![k-means multiple runs](/assets/images/blog/k-means-multiple_runs.gif)
__results from 5 runs of the k-means algorithm over the same datasets__

In a future post we'll look into mitigating this issue. We will also explore clustering data with higher dimensionality and finding the optimum k.
